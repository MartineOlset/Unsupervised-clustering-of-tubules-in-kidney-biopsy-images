{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideio\n",
    "import shapely\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import Polygon\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import openslide\n",
    "import math\n",
    "from tiatoolbox.tools import stainnorm\n",
    "from PIL import Image\n",
    "from tiatoolbox.tools.stainnorm import MacenkoNormalizer\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tubule Extraction from QuPath Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to export data from QuPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open **File**\n",
    "2. Open **Export objects as GeoJSON**.\n",
    "3. Export as `All objects` or `Selected objects` (use this if you only want one class).\n",
    "4. Enable `Pretty JSON` and `Export as FeatureCollection`.\n",
    "5. Compression as `None`\n",
    "6. Click **OK** to save the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading QuPath GeoJSON into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all QuPath GeoJSON annotation files from a folder into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the geosjon files are saved\n",
    "folder = r\"Annotations json\"  \n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Flatten features to DataFrame\n",
    "        df = pd.json_normalize(data[\"features\"])\n",
    "        df[\"file\"] = filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Merge to one dataframe\n",
    "annot_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the different image file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = annot_df['file'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictinoary with image-file-paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with images\n",
    "image_folder = r\"images\"\n",
    "\n",
    "image_file_paths = dict()\n",
    "for image in image_names:\n",
    "    name = os.path.splitext(image)[0]  # remove .geojson\n",
    "    svs_file = f\"{name}.svs\"\n",
    "    image_path = os.path.join(image_folder, svs_file)\n",
    "    image_file_paths[image] = image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding classes\n",
    "class_rows = annot_df['properties.classification.name'].tolist()\n",
    "classes = np.array(class_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acute damage: 204\n",
      "Atrophy: 184\n",
      "Chronic damage: 158\n",
      "Normal tubule: 263\n",
      "ROI: 12\n",
      "nan: 11\n"
     ]
    }
   ],
   "source": [
    "# Count number in class\n",
    "unique_classes, counts = np.unique(classes, return_counts=True)\n",
    "\n",
    "for cls, count in zip(unique_classes, counts):\n",
    "    print(f\"{cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on four target classes: Acute damage, Chronic damage, Normal tubule, and Atrophy, and remove all other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of wanted rows: 809\n",
      "number of rows removed: 23\n"
     ]
    }
   ],
   "source": [
    "wanted_classes = ['Acute damage', \"Chronic damage\", \"Normal tubule\", \"Atrophy\"]\n",
    "mask = annot_df['properties.classification.name'].isin(wanted_classes)\n",
    "\n",
    "wanted = mask.sum()\n",
    "remove = (~mask).sum()\n",
    "annot_df = annot_df[mask].reset_index(drop=True)\n",
    "\n",
    "print(f'number of wanted rows: {wanted}')\n",
    "print(f'number of rows removed: {remove}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acute damage: 204 (25.216%)\n",
      "Atrophy: 184 (22.744%)\n",
      "Chronic damage: 158 (19.530%)\n",
      "Normal tubule: 263 (32.509%)\n"
     ]
    }
   ],
   "source": [
    "class_rows = annot_df['properties.classification.name'].tolist()\n",
    "classes = np.array(class_rows)\n",
    "\n",
    "# Count number in class\n",
    "unique_classes, counts = np.unique(classes, return_counts=True)\n",
    "sum_classes = counts.sum()\n",
    "for cls, count in zip(unique_classes, counts):\n",
    "    prosent = count/sum_classes *100\n",
    "    print(f\"{cls}: {count} ({prosent:.3f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check wether some annotations are multipolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry.type\n",
       "Polygon         800\n",
       "MultiPolygon      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = annot_df['geometry.type'].value_counts()\n",
    "value_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each individual patch gets a bounding box, defined as the smallest axis-aligned rectangle that fully contains the tubule.  \n",
    "The coordinates of these boxes are computed in the format **(x, y, w, h)**, where:\n",
    "- x, y = top-left corner\n",
    "- w, h = width and height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding box\n",
    "\n",
    "Bounding boxes are computed for each tubule, and the coordinates are appended to a list named `bbox_to_plot`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_list = []\n",
    "bbox_to_plot = []\n",
    "class_name = []\n",
    "polygon_coord = []\n",
    "file_names = []\n",
    "polygon_type = []\n",
    "\n",
    "\n",
    "for index, row in annot_df.iterrows():\n",
    "    name = row['properties.classification.name']      # name\n",
    "    class_name.append(name)\n",
    "    image_name = row['file']                          # file-name\n",
    "    file_names.append(image_name)\n",
    "    geom_type = row['geometry.type']                  # geometry\n",
    "    polygon_type.append(geom_type)\n",
    "    coordinates = row['geometry.coordinates']        # coordinates\n",
    "    polygon_coord.append(coordinates)\n",
    "\n",
    "\n",
    "    if geom_type == 'MultiPolygon':\n",
    "        coord = coordinates[0][0]  \n",
    "    else:\n",
    "        coord = coordinates[0]\n",
    "    polygon = Polygon(coord)\n",
    "\n",
    "\n",
    "    # Bounding box with margin\n",
    "    bbox = list(polygon.bounds)  # (minx, miny, maxx, maxy)\n",
    "    bbox_list.append(bbox)\n",
    "    \n",
    "    bbox = [math.ceil(x) for x in bbox]\n",
    "    bbox[2] = bbox[2] - bbox[0]  # width\n",
    "    bbox[3] = bbox[3] - bbox[1]  # height\n",
    "    \n",
    "    margin_width = max(1, math.ceil(bbox[2]*0.01))\n",
    "    margin_height = max(1, math.ceil(bbox[3]*0.01))\n",
    "    bbox[0], bbox[1] = bbox[0] - margin_width, bbox[1] - margin_height\n",
    "    bbox[2], bbox[3] = bbox[2] + (2*margin_width), bbox[3] + (2*margin_height)\n",
    "    bbox_to_plot.append(tuple(bbox))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centered bounding box\n",
    "\n",
    "These bounding boxes are computed so that the tubule center is placed at the center of the box. The coordinates of each box are appended to a list called `centered_patches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_patches = []\n",
    "for index, row in annot_df.iterrows():\n",
    "    geom_type = row['geometry.type']\n",
    "    coordinates = row['geometry.coordinates']\n",
    "    \n",
    "    if geom_type == 'MultiPolygon':\n",
    "        coord = coordinates[0][0]\n",
    "    else:\n",
    "        coord = coordinates[0]\n",
    "    \n",
    "    polygon = Polygon(coord)\n",
    "    cx, cy = polygon.centroid.x, polygon.centroid.y\n",
    "    \n",
    "    height = bbox_to_plot[index][3] \n",
    "    width = bbox_to_plot[index][2] \n",
    "    size = max(width, height) + 70   # The lagrest of width and height, + 70 pixel margin\n",
    "    half_size = size // 2\n",
    "    \n",
    "    x0, y0 = int(cx - half_size), int(cy - half_size)\n",
    "    centered_patches.append((x0, y0, size, size))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual_df is a DataFrame with only the information necessary for visualizing/plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>bounding_box_for_plot</th>\n",
       "      <th>centered_patch</th>\n",
       "      <th>class_name</th>\n",
       "      <th>polygon_coord</th>\n",
       "      <th>file</th>\n",
       "      <th>polygon_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50450.0, 17426.0, 50666.0, 17706.0]</td>\n",
       "      <td>(50447, 17423, 222, 286)</td>\n",
       "      <td>(50384, 17383, 356, 356)</td>\n",
       "      <td>Normal tubule</td>\n",
       "      <td>[[[50507, 17426], [50503, 17428], [50500, 1742...</td>\n",
       "      <td>2016_220543_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[50768.0, 17737.0, 51010.0, 17974.0]</td>\n",
       "      <td>(50765, 17734, 248, 243)</td>\n",
       "      <td>(50722, 17697, 318, 318)</td>\n",
       "      <td>Normal tubule</td>\n",
       "      <td>[[[50860, 17737], [50858, 17738], [50855, 1773...</td>\n",
       "      <td>2016_220543_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[50979.0, 17543.0, 51206.0, 17828.0]</td>\n",
       "      <td>(50976, 17540, 233, 291)</td>\n",
       "      <td>(50906, 17503, 361, 361)</td>\n",
       "      <td>Normal tubule</td>\n",
       "      <td>[[[51081, 17543], [51079, 17544], [51077, 1754...</td>\n",
       "      <td>2016_220543_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[50424.0, 17693.0, 50545.0, 17830.0]</td>\n",
       "      <td>(50422, 17691, 125, 141)</td>\n",
       "      <td>(50378, 17654, 211, 211)</td>\n",
       "      <td>Normal tubule</td>\n",
       "      <td>[[[50476, 17693], [50474, 17694], [50470, 1769...</td>\n",
       "      <td>2016_220543_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[50526.0, 17612.0, 50770.0, 18052.0]</td>\n",
       "      <td>(50523, 17607, 250, 450)</td>\n",
       "      <td>(50389, 17593, 520, 520)</td>\n",
       "      <td>Normal tubule</td>\n",
       "      <td>[[[50729, 17612], [50727, 17613], [50725, 1761...</td>\n",
       "      <td>2016_220543_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>[54936.0, 25912.0, 55625.0, 26401.0]</td>\n",
       "      <td>(54929, 25907, 703, 499)</td>\n",
       "      <td>(54918, 25786, 773, 773)</td>\n",
       "      <td>Chronic damage</td>\n",
       "      <td>[[[55545, 25912], [55544, 25913], [55540, 2591...</td>\n",
       "      <td>2021_222456_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>[55620.0, 26939.0, 55842.0, 27270.5]</td>\n",
       "      <td>(55617, 26935, 228, 340)</td>\n",
       "      <td>(55519, 26898, 410, 410)</td>\n",
       "      <td>Chronic damage</td>\n",
       "      <td>[[[55704, 26939], [55703, 26940], [55701, 2694...</td>\n",
       "      <td>2021_222456_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>[55155.0, 26269.0, 55483.0, 26589.0]</td>\n",
       "      <td>(55151, 26265, 336, 328)</td>\n",
       "      <td>(55107, 26234, 406, 406)</td>\n",
       "      <td>Chronic damage</td>\n",
       "      <td>[[[55470, 26269], [55469, 26270], [55464, 2627...</td>\n",
       "      <td>2021_222456_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>[55427.0, 26238.0, 55700.0, 26493.0]</td>\n",
       "      <td>(55424, 26235, 279, 261)</td>\n",
       "      <td>(55383, 26189, 349, 349)</td>\n",
       "      <td>Chronic damage</td>\n",
       "      <td>[[[55554, 26238], [55552, 26239], [55550, 2624...</td>\n",
       "      <td>2021_222456_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>[55335.0, 27103.0, 55698.0, 27516.0]</td>\n",
       "      <td>(55331, 27098, 371, 423)</td>\n",
       "      <td>(55278, 27024, 493, 493)</td>\n",
       "      <td>Chronic damage</td>\n",
       "      <td>[[[55566, 27103], [55565, 27104], [55563, 2710...</td>\n",
       "      <td>2021_222456_ANON.geojson</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bounding_box     bounding_box_for_plot  \\\n",
       "0    [50450.0, 17426.0, 50666.0, 17706.0]  (50447, 17423, 222, 286)   \n",
       "1    [50768.0, 17737.0, 51010.0, 17974.0]  (50765, 17734, 248, 243)   \n",
       "2    [50979.0, 17543.0, 51206.0, 17828.0]  (50976, 17540, 233, 291)   \n",
       "3    [50424.0, 17693.0, 50545.0, 17830.0]  (50422, 17691, 125, 141)   \n",
       "4    [50526.0, 17612.0, 50770.0, 18052.0]  (50523, 17607, 250, 450)   \n",
       "..                                    ...                       ...   \n",
       "804  [54936.0, 25912.0, 55625.0, 26401.0]  (54929, 25907, 703, 499)   \n",
       "805  [55620.0, 26939.0, 55842.0, 27270.5]  (55617, 26935, 228, 340)   \n",
       "806  [55155.0, 26269.0, 55483.0, 26589.0]  (55151, 26265, 336, 328)   \n",
       "807  [55427.0, 26238.0, 55700.0, 26493.0]  (55424, 26235, 279, 261)   \n",
       "808  [55335.0, 27103.0, 55698.0, 27516.0]  (55331, 27098, 371, 423)   \n",
       "\n",
       "               centered_patch      class_name  \\\n",
       "0    (50384, 17383, 356, 356)   Normal tubule   \n",
       "1    (50722, 17697, 318, 318)   Normal tubule   \n",
       "2    (50906, 17503, 361, 361)   Normal tubule   \n",
       "3    (50378, 17654, 211, 211)   Normal tubule   \n",
       "4    (50389, 17593, 520, 520)   Normal tubule   \n",
       "..                        ...             ...   \n",
       "804  (54918, 25786, 773, 773)  Chronic damage   \n",
       "805  (55519, 26898, 410, 410)  Chronic damage   \n",
       "806  (55107, 26234, 406, 406)  Chronic damage   \n",
       "807  (55383, 26189, 349, 349)  Chronic damage   \n",
       "808  (55278, 27024, 493, 493)  Chronic damage   \n",
       "\n",
       "                                         polygon_coord  \\\n",
       "0    [[[50507, 17426], [50503, 17428], [50500, 1742...   \n",
       "1    [[[50860, 17737], [50858, 17738], [50855, 1773...   \n",
       "2    [[[51081, 17543], [51079, 17544], [51077, 1754...   \n",
       "3    [[[50476, 17693], [50474, 17694], [50470, 1769...   \n",
       "4    [[[50729, 17612], [50727, 17613], [50725, 1761...   \n",
       "..                                                 ...   \n",
       "804  [[[55545, 25912], [55544, 25913], [55540, 2591...   \n",
       "805  [[[55704, 26939], [55703, 26940], [55701, 2694...   \n",
       "806  [[[55470, 26269], [55469, 26270], [55464, 2627...   \n",
       "807  [[[55554, 26238], [55552, 26239], [55550, 2624...   \n",
       "808  [[[55566, 27103], [55565, 27104], [55563, 2710...   \n",
       "\n",
       "                         file polygon_type  \n",
       "0    2016_220543_ANON.geojson      Polygon  \n",
       "1    2016_220543_ANON.geojson      Polygon  \n",
       "2    2016_220543_ANON.geojson      Polygon  \n",
       "3    2016_220543_ANON.geojson      Polygon  \n",
       "4    2016_220543_ANON.geojson      Polygon  \n",
       "..                        ...          ...  \n",
       "804  2021_222456_ANON.geojson      Polygon  \n",
       "805  2021_222456_ANON.geojson      Polygon  \n",
       "806  2021_222456_ANON.geojson      Polygon  \n",
       "807  2021_222456_ANON.geojson      Polygon  \n",
       "808  2021_222456_ANON.geojson      Polygon  \n",
       "\n",
       "[809 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visual_df is a DataFrame with only the information necessary for visualizing/plotting\n",
    "visual_df = pd.DataFrame({\n",
    "    'bounding_box': bbox_list,\n",
    "    'bounding_box_for_plot': bbox_to_plot,\n",
    "    'centered_patch': centered_patches,\n",
    "    'class_name': class_name,\n",
    "    'polygon_coord':polygon_coord, \n",
    "    'file': file_names,\n",
    "    'polygon_type': polygon_type\n",
    "})\n",
    "\n",
    "visual_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping histology slides into smaller regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tubules lie outside the current region of interest (ROI), so we can’t use it to crop the histological slide. We need a new ROI that includes all tubules. We’ll compute the global bounding box by taking the minimum and maximum x and y coordinates across all tubule annotations, then derive the width, height and top-left corner. Finally, we store the crop info in the dictionary `image_slides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slides = dict()\n",
    "margin = 100\n",
    "\n",
    "for i in range(len(image_names)):\n",
    "    name = image_names[i]\n",
    "    df = visual_df[visual_df['file'] == name]\n",
    "\n",
    "    min_x_val = math.floor(min(bbox[0] for bbox in df['bounding_box']))-margin\n",
    "    min_y_val = math.floor(min(bbox[1] for bbox in df['bounding_box']))-margin\n",
    "    max_x_val = math.ceil(max(bbox[2] for bbox in df['bounding_box']))+margin\n",
    "    max_y_val = math.ceil(max(bbox[3] for bbox in df['bounding_box']))+margin\n",
    "    \n",
    "    width = int(abs(max_x_val - min_x_val))\n",
    "    height = int(abs(max_y_val - min_y_val))\n",
    "    top_corner = (min_x_val, min_y_val)  # the top-left corner of the patch\n",
    "\n",
    "    image_slides[name] = {\n",
    "        \"file\": name,\n",
    "        \"min_x_val\": min_x_val,\n",
    "        \"min_y_val\": min_y_val,   \n",
    "        \"max_x_val\": max_x_val,\n",
    "        \"max_y_val\": max_y_val,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"top_corner\": top_corner\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histology slides are cropped using the ROI parameters stored in image_slides. The cropped images are saved in the dictionary `slides_cropped`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_cropped = dict()\n",
    "for name, dimensions in image_slides.items():\n",
    "    top_corner = dimensions['top_corner']\n",
    "    width = dimensions['width']\n",
    "    height = dimensions['height']\n",
    "    path = image_file_paths[name]\n",
    "    slide = openslide.OpenSlide(path)\n",
    "    slides_cropped[name] = slide.read_region(location=top_corner, level=0, size=(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folders for patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not use all outputs. Set True on the folders you need, **but be careful** – some folders depend on others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the folders with data get saved\n",
    "OUT_DIR = Path(\"../data\")\n",
    "\n",
    "ENABLED = {\n",
    "    \"tubule_patches\": True,\n",
    "    \"tubule_patches_scaled\": False,   # depends on tubule_patches\n",
    "    \"center_patches\": True,           # depends on tubule_patches\n",
    "    \"masked_patches_center\": True,    # depends on tubule_patches + center_patches\n",
    "    \"masked_patches\": True,           # depends on tubule_patches\n",
    "    \"masked_patches_scaled\": False,   # depends on tubule_patches + masked_patches\n",
    "}\n",
    "\n",
    "folders = [key for key, val in ENABLED.items() if val]\n",
    "for name in folders:\n",
    "    (OUT_DIR / name).mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tubule_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_prefix = {\n",
    "    \"Normal tubule\": \"normal_tubule\",\n",
    "    \"Acute damage\": \"acute_damage\",\n",
    "    \"Chronic damage\": \"chronic_damage\",\n",
    "    \"Atrophy\": \"atrophy\"\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(visual_df)):\n",
    "    file = visual_df.iloc[i, 5]\n",
    "    slide = slides_cropped[file]\n",
    "    name = visual_df.iloc[i,3]\n",
    "    prefix = name_to_prefix.get(name) \n",
    "    \n",
    "    # Convert global coordinates to local bbox coordinates\n",
    "    global_x, global_y, width, height = visual_df.iloc[i, 1]  \n",
    "    region_x, region_y = image_slides[file]['top_corner']\n",
    "    local_x = global_x-region_x\n",
    "    local_y = global_y-region_y\n",
    "    \n",
    "    tile = slide.crop((local_x,local_y,local_x+width,local_y+height))\n",
    "    tile = tile.convert(\"RGB\") \n",
    "    tile.save(f'../data/tubule_patches/{prefix}_p{i}.png', 'PNG') # save image based on class-name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color normalization of tubule_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a target image and use it as referance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with the target image\n",
    "target_img = np.array(Image.open(r\"target_image/target_image.png\"))\n",
    "\n",
    "normaliser = MacenkoNormalizer()\n",
    "normaliser.fit(target_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color noemalizing the tubule_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tubule patches\n",
    "input_dir = r\"../data/tubule_patches\"\n",
    "output_dir = r\"../data/tubule_patches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all images in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    \n",
    "    # Open the image \n",
    "    path = os.path.join(input_dir, filename)\n",
    "    img = Image.open(path)   \n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Apply color normalization\n",
    "    img_norm = normaliser.transform(img_np)\n",
    "    img_norm_img = Image.fromarray(img_norm)\n",
    "\n",
    "    # Save the normalized image to the output directory \n",
    "    img_norm_img.save(os.path.join(output_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## center_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(r\"../data/tubule_patches\")\n",
    "output_dir = Path(r\"../data/center_patches\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "out_dir = Path(\"../data/center_patches\")\n",
    "center_patches = True\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    \n",
    "    if not out_dir.exists(): \n",
    "        center_patches = False\n",
    "        continue\n",
    "    \n",
    "    path = input_dir / filename\n",
    "    \n",
    "    # Parse index from filename\n",
    "    nr = int(path.stem.split(\"_\")[-1][1:])\n",
    "\n",
    "    # Convert global coordinates to local bbox coordinates\n",
    "    bbox_x, bbox_y, bbox_w, bbox_h = visual_df.iloc[nr, 1]\n",
    "    global_x, global_y, width, height = visual_df.iloc[nr, 2]\n",
    "    local_x = int(global_x - bbox_x)\n",
    "    local_y = int(global_y - bbox_y)\n",
    "    \n",
    "    # Crop and save\n",
    "    with Image.open(path) as img:\n",
    "        tile = img.crop((local_x, local_y, local_x + int(width), local_y + int(height)))\n",
    "        tile.save(output_dir / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tubul_patches_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling images\n",
    "target_size = (224, 224)  # width, height\n",
    "input_folder = \"../data/tubule_patches\"\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    #change size\n",
    "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    new_filename = f\"{name}_scaled{ext}\"\n",
    "\n",
    "    save_path = os.path.join(\"../data/tubule_patches_scaled\", new_filename)\n",
    "    cv2.imwrite(save_path, img_resized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {\n",
    "    \"Normal tubule\": \"normal_tubule\",\n",
    "    \"Acute damage\": \"acute_damage\",\n",
    "    \"Chronic damage\": \"chronic_damage\",\n",
    "    \"Atrophy\": \"atrophy\"}\n",
    "out_dir = Path(\"../data/masked_patches\")\n",
    "masked_patch = True\n",
    "\n",
    "#bbox patches   \n",
    "for i in range(len(visual_df)):\n",
    "    \n",
    "    if not out_dir.exists(): \n",
    "        masked_patch = False\n",
    "        continue\n",
    "\n",
    "    name = visual_df.iloc[i,3]\n",
    "    polygon_type = visual_df.iloc[i, 6]\n",
    "\n",
    "    prefix = file_dict[name]\n",
    "    filename = f'../data/tubule_patches/{prefix}_p{i}.png'\n",
    "    new_name = f'../data/masked_patches/{prefix}_p{i}.png'\n",
    "\n",
    "    image = cv2.imread(filename)\n",
    "    bbox = visual_df.iloc[i, 1]\n",
    "    bbox = tuple([int(x) for x in bbox])\n",
    "\n",
    "\n",
    "    if polygon_type == \"MultiPolygon\":\n",
    "        coords = visual_df['polygon_coord'][i][0][0]\n",
    "    else: \n",
    "        coords = visual_df['polygon_coord'][i][0]\n",
    "\n",
    "    poly = Polygon(coords)\n",
    "    poly_expanded = poly.buffer(5)\n",
    "    \n",
    "    polygon_points = np.array(poly_expanded.exterior.coords).astype('int32')  # some were floats, convert all to int \n",
    "    polygon_points [:, 0] = (polygon_points [:, 0]-bbox[0])\n",
    "    polygon_points [:, 1] = (polygon_points [:, 1]-bbox[1])\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8) \n",
    "    cv2.fillPoly(mask, [polygon_points], (255))\n",
    "\n",
    "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    im = Image.fromarray(foreground)\n",
    "    cv2.imwrite(new_name, foreground) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked_patches_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling images\n",
    "target_size = (224, 224)  # width, height\n",
    "input_folder = \"../data/masked_patches\"\n",
    "out_dir = Path(\"../data/masked_patches_scaled\")\n",
    "\n",
    "if not out_dir.exists() or not masked_patch:\n",
    "    pass\n",
    "else: \n",
    "    for filename in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        #change size\n",
    "        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        new_filename = f\"{name}_scaled{ext}\"\n",
    "\n",
    "        save_path = os.path.join(\"../data/masked_patches_scaled\", new_filename)\n",
    "        cv2.imwrite(save_path, img_resized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked_patches_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lagrest tubulu size\n",
    "max_width = max(box[2] for box in bbox_to_plot)\n",
    "max_height = max(box[3] for box in bbox_to_plot)\n",
    "max_size = max(max_width, max_height) + 70  # lagrest size + 70 pixel margin\n",
    "half_size = size // 2\n",
    "\n",
    "out_dir = Path(\"../data/masked_patches_center\")\n",
    "\n",
    "if not out_dir.exists() or not center_patches:\n",
    "    pass\n",
    "for i in range(len(visual_df)):\n",
    "\n",
    "    name = visual_df.iloc[i,3]\n",
    "    polygon_type = visual_df.iloc[i, 6]\n",
    "\n",
    "    prefix = file_dict[name]\n",
    "    filename = f'../data/center_patches/{prefix}_p{i}.png'\n",
    "    new_name = f'../data/masked_patches_center/{prefix}_p{i}.png'\n",
    "\n",
    "    image = cv2.imread(filename)\n",
    "    bbox = visual_df.iloc[i, 2]\n",
    "    bbox = tuple([int(x) for x in bbox])\n",
    "\n",
    "    if polygon_type == \"MultiPolygon\":\n",
    "        coords = visual_df['polygon_coord'][i][0][0]\n",
    "    else: \n",
    "        coords = visual_df['polygon_coord'][i][0]\n",
    "\n",
    "    poly = Polygon(coords)\n",
    "    poly_expanded = poly.buffer(5)\n",
    "    \n",
    "    polygon_points = np.array(poly_expanded.exterior.coords).astype('int32')  # some were floats, convert all to int \n",
    "    polygon_points [:, 0] = (polygon_points [:, 0]-bbox[0])\n",
    "    polygon_points [:, 1] = (polygon_points [:, 1]-bbox[1])\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8) \n",
    "    cv2.fillPoly(mask, [polygon_points], (255))\n",
    "\n",
    "    # calculate the connected componante:  cv2.conectedComponentWithStats connected--> calculate the box\n",
    "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    size = centered_patches[i][2]\n",
    "    d_size = (max_size-size)\n",
    "    pad_each = d_size // 2\n",
    "    top = left = pad_each\n",
    "    bottom = right = d_size - pad_each         # assigns the extra pixel when d_size is odd\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        foreground, top, bottom, left, right,\n",
    "        borderType=cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "    )\n",
    "\n",
    "    cv2.imwrite(new_name, padded) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Praksis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
